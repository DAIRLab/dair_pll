<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dair_pll.tensor_utils &mdash; dair_pll v0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=2fea6348"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            dair_pll
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Submodules:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.quaternion.html">dair_pll.quaternion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.state_space.html">dair_pll.state_space</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.drake_utils.html">dair_pll.drake_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.tensor_utils.html">dair_pll.tensor_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.hyperparameter.html">dair_pll.hyperparameter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.data_config.html">dair_pll.data_config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.experiment_config.html">dair_pll.experiment_config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.file_utils.html">dair_pll.file_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.inertia.html">dair_pll.inertia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.integrator.html">dair_pll.integrator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.system.html">dair_pll.system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.deep_support_function.html">dair_pll.deep_support_function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.geometry.html">dair_pll.geometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.drake_state_converter.html">dair_pll.drake_state_converter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.multibody_terms.html">dair_pll.multibody_terms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.urdf_utils.html">dair_pll.urdf_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.drake_system.html">dair_pll.drake_system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.vis_utils.html">dair_pll.vis_utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.wandb_manager.html">dair_pll.wandb_manager</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.multibody_learnable_system.html">dair_pll.multibody_learnable_system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.dataset_management.html">dair_pll.dataset_management</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.experiment.html">dair_pll.experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.deep_learnable_model.html">dair_pll.deep_learnable_model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.deep_learnable_system.html">dair_pll.deep_learnable_system</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dair_pll.drake_experiment.html">dair_pll.drake_experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bibliography.html">Bibliography</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">dair_pll</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dair_pll.tensor_utils</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for dair_pll.tensor_utils</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Tensor utility functions.</span>

<span class="sd">Contains various utility functions for common tensor operations required</span>
<span class="sd">throughout the package. All such future functions should be placed here,</span>
<span class="sd">with the following exceptions:</span>

<span class="sd">    * Utilities for operating directly on :math:`SO(3)` should be placed in</span>
<span class="sd">      :py:mod:`dair_pll.quaternion`</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>


<div class="viewcode-block" id="tile_dim">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.tile_dim">[docs]</a>
<span class="k">def</span> <span class="nf">tile_dim</span><span class="p">(</span><span class="n">tiling_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">copies</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tiles tensor along specified dimension.</span>

<span class="sd">    Args:</span>
<span class="sd">        tiling_tensor: ``(n_0, ..., n_{k-1})`` tensor.</span>
<span class="sd">        copies: number of copies, ``copies &gt;= 1``.</span>
<span class="sd">        dim: dimension to be tiled, ``-k &lt;= dim &lt;= k - 1``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(n_0, ..., n * n_dim, ... n_{k-1})`` tiled tensor.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: when ``copies`` is not a strictly-positive integer</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">copies</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;Tiling count should be positive int, got </span><span class="si">{</span><span class="n">copies</span><span class="si">}</span><span class="s1"> instead.&#39;</span><span class="p">)</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">tiling_tensor</span><span class="p">]</span> <span class="o">*</span> <span class="n">copies</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span></div>



<div class="viewcode-block" id="tile_last_dim">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.tile_last_dim">[docs]</a>
<span class="k">def</span> <span class="nf">tile_last_dim</span><span class="p">(</span><span class="n">tiling_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">copies</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tile right dimension (``-1``) via :py:func:`tile_dim`&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tile_dim</span><span class="p">(</span><span class="n">tiling_tensor</span><span class="p">,</span> <span class="n">copies</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>



<div class="viewcode-block" id="tile_penultimate_dim">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.tile_penultimate_dim">[docs]</a>
<span class="k">def</span> <span class="nf">tile_penultimate_dim</span><span class="p">(</span><span class="n">tiling_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">copies</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Tile second-to-last dimension (``-2``) :py:func:`tile_dim`&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tile_dim</span><span class="p">(</span><span class="n">tiling_tensor</span><span class="p">,</span> <span class="n">copies</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span></div>



<div class="viewcode-block" id="pbmm">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.pbmm">[docs]</a>
<span class="k">def</span> <span class="nf">pbmm</span><span class="p">(</span><span class="n">t_1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">t_2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiplies matrices with optional batching.</span>

<span class="sd">    Wrapper function that performs a final-axes (``-2,-1``) matrix-matrix,</span>
<span class="sd">    vector-matrix, matrix-vector, or vector-vector product depending on the</span>
<span class="sd">    shape of ``t_1`` and ``t_2``. The following logic is used:</span>

<span class="sd">        * do a matrix-matrix multiplication if both factors have dimension at</span>
<span class="sd">          least two, and broadcast to the larger (inferred) batch.</span>
<span class="sd">        * do a vector-matrix / matrix-vector multiplication if one factor is</span>
<span class="sd">          a vector and the other has dimension ``&gt;= 2``</span>
<span class="sd">        * do a vector-vector multiplication if both factors are vectors.</span>


<span class="sd">    Args:</span>
<span class="sd">        t_1: ``(*, l, m)`` or ``(l, m)`` or ``(m,)`` left tensor factor.</span>
<span class="sd">        t_2: ``(*, m, n)`` or ``(m, n)`` or ``(m,)`` right tensor factor.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(*, l, n) if l, n &gt; 1 or (*, l) if l &gt; 1, n = 1 or (*, n)</span>
<span class="sd">        if l = 1, or n &gt; 1`` or scalar ``if dim(t_1) == dim(t_2) == 1`` product</span>
<span class="sd">        tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">t_1_dim</span> <span class="o">=</span> <span class="n">t_1</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
    <span class="n">t_2_dim</span> <span class="o">=</span> <span class="n">t_2</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
    <span class="n">needs_squeeze</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># case 1: single dot product</span>
    <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">t_1_dim</span><span class="p">,</span> <span class="n">t_2_dim</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># dot product</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">t_1</span> <span class="o">*</span> <span class="n">t_2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="c1"># temporarily expand dimension for vector-matrix product</span>
    <span class="k">if</span> <span class="n">t_1_dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">t_1</span> <span class="o">=</span> <span class="n">t_1</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">t_1_dim</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">needs_squeeze</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
    <span class="k">elif</span> <span class="n">t_2_dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">t_2</span> <span class="o">=</span> <span class="n">t_2</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">t_2_dim</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">needs_squeeze</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="c1"># cases 2 and 3: matrix product</span>
    <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">t_1_dim</span><span class="p">,</span> <span class="n">t_2_dim</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># match batching</span>
        <span class="k">if</span> <span class="n">t_1_dim</span> <span class="o">&lt;</span> <span class="n">t_2_dim</span><span class="p">:</span>
            <span class="n">t_1</span> <span class="o">=</span> <span class="n">t_1</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">t_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="n">t_1_dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">t_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">t_1_dim</span> <span class="o">&gt;</span> <span class="n">t_2_dim</span><span class="p">:</span>
            <span class="n">t_2</span> <span class="o">=</span> <span class="n">t_2</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">t_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="n">t_2_dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">t_2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># pylint: disable=E1103</span>
        <span class="n">product</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">t_1</span><span class="p">,</span> <span class="n">t_2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">product</span> <span class="o">=</span> <span class="n">t_1</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">t_2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">needs_squeeze</span><span class="p">:</span>
        <span class="n">product</span> <span class="o">=</span> <span class="n">product</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">needs_squeeze</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">product</span></div>



<div class="viewcode-block" id="deal">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.deal">[docs]</a>
<span class="k">def</span> <span class="nf">deal</span><span class="p">(</span><span class="n">dealing_tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
         <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
         <span class="n">keep_dim</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts dim of tensor to list.</span>

<span class="sd">    Example:</span>
<span class="sd">        Let ``t`` be a 3-dimensional tensor of shape ``(3,5,3)`` such that::</span>

<span class="sd">            t[:, i, :] == torch.eye(3).</span>

<span class="sd">        Then ``deal(t, dim=1)`` returns a list of 5 ``(3,3)`` identity tensors,</span>
<span class="sd">        and ``deal(t, dim=1, keep_dim=True)`` returns a list of ``(3,1,3)``</span>
<span class="sd">        tensors.</span>

<span class="sd">    Args:</span>
<span class="sd">        dealing_tensor: ``(n_0, ..., n_dim, ..., n_{k-1})`` shaped tensor.</span>
<span class="sd">        dim: tensor dimension to deal, ``-k &lt;= dim &lt;= k-1``.</span>
<span class="sd">        keep_dim: whether to squeeze list items along ``dim``.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of dealt sub-tensors of shape ``(..., n_{dim-1}, {n_dim+1}, ...)``</span>
<span class="sd">        or ``(..., n_{dim-1}, 1, {n_dim+1}, ...)``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tensor_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">dealing_tensor</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">keep_dim</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tensor_list</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">tensor_i</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">tensor_i</span> <span class="ow">in</span> <span class="n">tensor_list</span><span class="p">]</span></div>



<div class="viewcode-block" id="skew_symmetric">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.skew_symmetric">[docs]</a>
<span class="k">def</span> <span class="nf">skew_symmetric</span><span class="p">(</span><span class="n">vectors</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Converts vectors in :math:`\mathbb{R}^3` into skew-symmetric form.</span>

<span class="sd">    Converts vector(s) :math:`v` in ``vectors`` into skew-symmetric matrix:</span>

<span class="sd">    .. math::</span>

<span class="sd">        S(v) = -S(v)^T = \begin{bmatrix} 0 &amp; -v_3 &amp; v_2 \\</span>
<span class="sd">        v_3 &amp; 0 &amp; -v_1 \\</span>
<span class="sd">        -v_2 &amp; v_1 &amp; 0 \end{bmatrix}</span>

<span class="sd">    Args:</span>
<span class="sd">        vectors: ``(*, 3)`` vector(s) to convert to matrices</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(*, 3, 3)`` skew-symmetric matrices :math:`S(v)`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">zero</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">row_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">zero</span><span class="p">,</span> <span class="o">-</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">row_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">zero</span><span class="p">,</span> <span class="o">-</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">row_3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="o">-</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">zero</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">row_1</span><span class="p">,</span> <span class="n">row_2</span><span class="p">,</span> <span class="n">row_3</span><span class="p">),</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span></div>



<div class="viewcode-block" id="symmetric_offdiagonal">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.symmetric_offdiagonal">[docs]</a>
<span class="k">def</span> <span class="nf">symmetric_offdiagonal</span><span class="p">(</span><span class="n">vectors</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Converts vectors in :math:`\mathbb{R}^3` into symmetric off-diagonal</span>
<span class="sd">    form.  This is the same as skew symmetric except for the skew negative</span>
<span class="sd">    signs.</span>

<span class="sd">    Converts vector(s) :math:`v` in ``vectors`` into symmetric matrix:</span>

<span class="sd">    .. math::</span>

<span class="sd">        S(v) = S(v)^T = \begin{bmatrix} 0 &amp; v_3 &amp; v_2 \\</span>
<span class="sd">        v_3 &amp; 0 &amp; v_1 \\</span>
<span class="sd">        v_2 &amp; v_1 &amp; 0 \end{bmatrix}</span>

<span class="sd">    Args:</span>
<span class="sd">        vectors: ``(*, 3)`` vector(s) to convert to matrices</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(*, 3, 3)`` symmetric matrices :math:`S(v)`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">zero</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">row_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">zero</span><span class="p">,</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">row_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">zero</span><span class="p">,</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">row_3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">zero</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">row_1</span><span class="p">,</span> <span class="n">row_2</span><span class="p">,</span> <span class="n">row_3</span><span class="p">),</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span></div>



<div class="viewcode-block" id="batch_diagonal">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.batch_diagonal">[docs]</a>
<span class="k">def</span> <span class="nf">batch_diagonal</span><span class="p">(</span><span class="n">vectors</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Converts vectors to diagonal matrices.</span>

<span class="sd">    Take in an arbitrary batch of n-vectors and returns the same sized batch</span>
<span class="sd">    of (n, n) matrices such that::</span>

<span class="sd">        output[b_1, ..., b_k, :, :] == torch.diag(vectors[b_1, ..., b_k, :]).</span>

<span class="sd">    Code structure comes from thw following address:</span>

<span class="sd">        https://discuss.pytorch.org/t/batch-of-diagonal-matrix/13560</span>

<span class="sd">    Args:</span>
<span class="sd">        vectors: ``(*, n)`` batch of</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(*, n, n)`` batch of diagonal matrices</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># make a zero matrix, which duplicates the last dim of input</span>
    <span class="n">dims</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>

    <span class="c1"># stride across the first dimensions, and add one to get the diagonal of the</span>
    <span class="c1"># last dimension</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="n">output</span><span class="o">.</span><span class="n">stride</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="n">strides</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># stride and copy the input to the diagonal</span>
    <span class="n">output</span><span class="o">.</span><span class="n">as_strided</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">strides</span><span class="p">)</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>



<div class="viewcode-block" id="one_vector_block_diagonal">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.one_vector_block_diagonal">[docs]</a>
<span class="k">def</span> <span class="nf">one_vector_block_diagonal</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">vector_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes a block diagonal matrix with column vectors of ones as blocks.</span>

<span class="sd">    Associated with the mathematical symbol :math:`E`.</span>

<span class="sd">    Example:</span>
<span class="sd">        ::</span>

<span class="sd">            one_vector_block_diagonal(3, 2) == tensor([</span>
<span class="sd">                [1., 0., 0.],</span>
<span class="sd">                [1., 0., 0.],</span>
<span class="sd">                [0., 1., 0.],</span>
<span class="sd">                [0., 1., 0.],</span>
<span class="sd">                [0., 0., 1.],</span>
<span class="sd">                [0., 0., 1.]]).</span>

<span class="sd">    Args:</span>
<span class="sd">        num_blocks: number of columns.</span>
<span class="sd">        vector_length: number of ones in each matrix diagonal block.</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(n * vector_length, n)`` 0-1 tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">num_blocks</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">vector_length</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">num_blocks</span> <span class="o">*</span> <span class="n">vector_length</span><span class="p">,</span> <span class="n">num_blocks</span><span class="p">)</span></div>



<div class="viewcode-block" id="spatial_to_point_jacobian">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.spatial_to_point_jacobian">[docs]</a>
<span class="k">def</span> <span class="nf">spatial_to_point_jacobian</span><span class="p">(</span><span class="n">p_BoP_E</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Body-fixed translational velocity to spatial velocity Jacobian.</span>

<span class="sd">    Takes a batch of points :math:`[^{Bo}p^P]_E` fixed to body :math:`B` and</span>
<span class="sd">    expressed in some coordinates :math:`E`, and constructs the Jacobian of</span>
<span class="sd">    their linear velocity in some other frame :math:`A` w.r.t. the</span>
<span class="sd">    :math:`E`-coordinate spatial velocity of :math:`B` relative to :math:`A`.</span>

<span class="sd">    In detail, let the :math:`i`th element of the batch represent point ``Pi``</span>
<span class="sd">    as :math:`[^{Bo}p^{Pi}]_E`, and let Ao be fixed in A. The Jacobian</span>
<span class="sd">    calculated is</span>

<span class="sd">    .. math::</span>

<span class="sd">        J = \frac{\partial [^Av^{Pi}]_E }{\partial [^AV^B]_E}.</span>

<span class="sd">    We have that :math:`[^AV^B]_E = [^A\omega^B; ^{A}v^{Bo}]_E`, and from</span>
<span class="sd">    kinematics that</span>

<span class="sd">    .. math::</span>

<span class="sd">        ^Av^{Pi}= ^{A}v^{Bo} + ^A\omega^B \times ^{Bo}p^{Pi}.</span>

<span class="sd">    Thus, the Jacobian is of the form</span>

<span class="sd">    .. math::</span>

<span class="sd">       J = [-S([^{Bo}p^{Pi}]_E), I_3],</span>

<span class="sd">    where :math:`S` is calculated via :py:func:`skew_symmetric`.</span>

<span class="sd">    Args:</span>
<span class="sd">        p_BoP_E: ``(*, 3)``, body frame point(s) :math:`P` in coordinates</span>
<span class="sd">          :math:`E`</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(*, 3, 6)`` Jacobian tensor(s) :math:`J`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">left</span> <span class="o">=</span> <span class="o">-</span><span class="n">skew_symmetric</span><span class="p">(</span><span class="n">p_BoP_E</span><span class="p">)</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">right</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">p_BoP_E</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>



<div class="viewcode-block" id="rotation_matrix_from_one_vector">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.rotation_matrix_from_one_vector">[docs]</a>
<span class="k">def</span> <span class="nf">rotation_matrix_from_one_vector</span><span class="p">(</span><span class="n">directions</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Converts a batch of directions for specified axis, to a</span>
<span class="sd">    batch of rotation matrices.</span>

<span class="sd">    Specifically, if the ``i``\ th provided direction is ``d_i``, then the</span>
<span class="sd">    ``i``\ th returned rotation matrix ``R_i`` obeys::</span>

<span class="sd">        R_i[:, axis] == d_i.</span>

<span class="sd">    Reimplements the algorithm from Drake&#39;s</span>
<span class="sd">    :py:meth:`pydrake.math.RotationMatrix_[float].MakeFromOneVector`. For more</span>
<span class="sd">    details,</span>
<span class="sd">    see ``rotation_matrix.cc:L13`` at the following address:</span>

<span class="sd">        https://github.com/RobotLocomotion/drake/blob/d9c453d214ef715c89ab0e8553cae24900b7adde/math/rotation_matrix.cc#L13</span>

<span class="sd">    Args:</span>
<span class="sd">        directions: ``(*, 3)`` x/y/z directions.</span>
<span class="sd">        axis: ``0``, ``1``, or ``2`` depending on if ``directions`` are x, y, or</span>
<span class="sd">          z.</span>
<span class="sd">    Returns:</span>
<span class="sd">        ``(*, 3, 3)`` rotation matrix batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">axis</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">original_shape</span> <span class="o">=</span> <span class="n">directions</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">directions</span> <span class="o">=</span> <span class="n">directions</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">batch_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">directions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="n">column_a</span> <span class="o">=</span> <span class="n">directions</span> <span class="o">/</span> <span class="n">directions</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">min_a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">column_a</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">min_magnitude_a</span> <span class="o">=</span> <span class="n">directions</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">min_a</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">axis_i</span> <span class="o">=</span> <span class="n">min_a</span><span class="o">.</span><span class="n">indices</span>
    <span class="n">axis_j</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span>
    <span class="n">axis_k</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">magnitude_a_u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">min_magnitude_a</span> <span class="o">*</span> <span class="n">min_magnitude_a</span><span class="p">)</span>
    <span class="n">axis_c_correction</span> <span class="o">=</span> <span class="o">-</span><span class="n">min_magnitude_a</span> <span class="o">/</span> <span class="n">magnitude_a_u</span>

    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">column_b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">column_a</span><span class="p">)</span>
    <span class="n">column_b</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span>
             <span class="n">axis_j</span><span class="p">]</span> <span class="o">+=</span> <span class="o">-</span><span class="n">column_a</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">axis_k</span><span class="p">]</span> <span class="o">/</span> <span class="n">magnitude_a_u</span>
    <span class="n">column_b</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span>
             <span class="n">axis_k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">column_a</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">axis_j</span><span class="p">]</span> <span class="o">/</span> <span class="n">magnitude_a_u</span>

    <span class="n">column_c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">column_a</span><span class="p">)</span>
    <span class="n">column_c</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">axis_i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">magnitude_a_u</span>
    <span class="n">column_c</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span>
             <span class="n">axis_j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">axis_c_correction</span> <span class="o">*</span> <span class="n">column_a</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">axis_j</span><span class="p">]</span>
    <span class="n">column_c</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span>
             <span class="n">axis_k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">axis_c_correction</span> <span class="o">*</span> <span class="n">column_a</span><span class="p">[</span><span class="n">batch_range</span><span class="p">,</span> <span class="n">axis_k</span><span class="p">]</span>

    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">)]</span> <span class="o">*</span> <span class="mi">3</span>
    <span class="n">columns</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">=</span> <span class="n">column_a</span>
    <span class="n">columns</span><span class="p">[(</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">column_b</span>
    <span class="n">columns</span><span class="p">[(</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">column_c</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">original_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">3</span><span class="p">,))</span></div>



<div class="viewcode-block" id="broadcast_lorentz">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.broadcast_lorentz">[docs]</a>
<span class="k">def</span> <span class="nf">broadcast_lorentz</span><span class="p">(</span><span class="n">vectors</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Utility function that broadcasts scalars into Lorentz product cone</span>
<span class="sd">    format.</span>

<span class="sd">    This function maps a given vector :math:`v = [v_1, \dots, v_n]` in given</span>
<span class="sd">    batch ``vectors`` to</span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{bmatrix} v &amp; v_1 &amp; v_1 &amp; \cdots &amp; v_n &amp; v_n \end{bmatrix}.</span>

<span class="sd">    Args:</span>
<span class="sd">        vectors: ``(*, n)`` vectors to be broadcasted.</span>
<span class="sd">    Returns:</span>
<span class="sd">        ``(*, 3 * n)`` broadcasted vectors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_cones</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">double_vectors_shape</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_cones</span><span class="p">,)</span>
    <span class="n">vectors_tiled</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">double_vectors_shape</span><span class="p">)</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">vectors</span><span class="p">,</span> <span class="n">vectors_tiled</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span></div>



<div class="viewcode-block" id="project_lorentz">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.project_lorentz">[docs]</a>
<span class="k">def</span> <span class="nf">project_lorentz</span><span class="p">(</span><span class="n">vectors</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Utility function that projects vectors in Lorentz cone product.</span>

<span class="sd">    This function takes in a batch of vectors</span>

<span class="sd">    .. math::</span>

<span class="sd">        \begin{align}</span>
<span class="sd">        v &amp;= \begin{bmatrix} v_{n1} &amp; \cdots v_{nk} &amp; v_{t1} &amp; \cdots v_{tk}</span>
<span class="sd">        \end{bmatrix},\\</span>
<span class="sd">        v_{ni} &amp;\in \mathbb{R},\\</span>
<span class="sd">        v_{ti} &amp;\in \mathbb{R}^2,\\</span>
<span class="sd">        \end{align}</span>

<span class="sd">    and projects each :math:`v_i = [v_{ni} v_{ti}]` into the Lorentz cone</span>
<span class="sd">    :math:`L = \{ v_{ni} \geq ||v_{ti}||_2\}` via the following piecewise</span>
<span class="sd">    formula:</span>

<span class="sd">        * if :math:`v_i \in L`, it remains the same.</span>
<span class="sd">        * if :math:`v_i \in L^{\circ} = \{-v_{ni} \geq ||v_{ti}||_2\}` (the</span>
<span class="sd">          polar cone), replace it with :math:`0`.</span>
<span class="sd">        * if :math:`v_i \not\in L \cup L^\circ`, replace it with</span>

<span class="sd">          .. math::</span>

<span class="sd">            v = \begin{bmatrix} n &amp; \frac{n}{||v_{ti}||_2}v_{ti}</span>
<span class="sd">            \end{bmatrix},</span>

<span class="sd">          where :math:`n = \frac{1}{2}(v_{ni} + ||v_{ti}||_2)`.</span>


<span class="sd">    Args:</span>
<span class="sd">        vectors: ``(*, 3 * n)`` vectors to be projected.</span>
<span class="sd">    Returns:</span>
<span class="sd">        ``(*, 3 * n)`` broadcasted vectors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=too-many-locals</span>
    <span class="k">assert</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">n_cones</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="mi">3</span>

    <span class="n">normals</span> <span class="o">=</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">n_cones</span><span class="p">]</span>
    <span class="n">tangents</span> <span class="o">=</span> <span class="n">vectors</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">n_cones</span><span class="p">:]</span>
    <span class="n">tangent_vectors_shape</span> <span class="o">=</span> <span class="n">tangents</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_cones</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">tangent_norms</span> <span class="o">=</span> <span class="n">tangents</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tangent_vectors_shape</span><span class="p">)</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">not_in_lorentz_cone</span> <span class="o">=</span> <span class="n">tangent_norms</span> <span class="o">&gt;</span> <span class="n">normals</span>
    <span class="n">in_polar_cone</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tangent_norms</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="n">normals</span><span class="p">)</span>
    <span class="n">in_neither_cone</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span>
                                   <span class="p">(</span><span class="o">~</span><span class="n">in_polar_cone</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">not_in_lorentz_cone</span><span class="p">)</span>

    <span class="n">in_polar_mask</span> <span class="o">=</span> <span class="n">broadcast_lorentz</span><span class="p">(</span><span class="n">in_polar_cone</span><span class="p">)</span>
    <span class="n">in_neither_mask</span> <span class="o">=</span> <span class="n">broadcast_lorentz</span><span class="p">(</span><span class="n">in_neither_cone</span><span class="p">)</span>

    <span class="n">projected_vectors</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

    <span class="n">projected_vectors</span><span class="p">[</span><span class="n">in_polar_mask</span><span class="p">]</span> <span class="o">*=</span> <span class="mf">0.</span>

    <span class="n">normals_rescaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">normals</span> <span class="o">+</span> <span class="n">tangent_norms</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="n">tangent_normalizer</span> <span class="o">=</span> <span class="n">normals_rescaled</span> <span class="o">/</span> <span class="n">tangent_norms</span>
    <span class="n">tangent_rescaled</span> <span class="o">=</span> <span class="n">tangents</span> <span class="o">*</span> <span class="n">tangent_normalizer</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span>
        <span class="n">tangent_vectors_shape</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tangents</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">vectors_rescaled</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">normals_rescaled</span><span class="p">,</span> <span class="n">tangent_rescaled</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">projected_vectors</span><span class="p">[</span><span class="n">in_neither_mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">vectors_rescaled</span><span class="p">[</span><span class="n">in_neither_mask</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">projected_vectors</span></div>


<div class="viewcode-block" id="sappy_reorder_mat">
<a class="viewcode-back" href="../../dair_pll.tensor_utils.html#dair_pll.tensor_utils.sappy_reorder_mat">[docs]</a>
<span class="k">def</span> <span class="nf">sappy_reorder_mat</span><span class="p">(</span><span class="n">n_cones</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Generates a 0-1 matrix that reorders force variable indices between</span>
<span class="sd">    ``dair_pll`` ordering and ``sappy`` ordering.</span>

<span class="sd">    ``dair_pll`` orders force variables as</span>

<span class="sd">    .. math::</span>

<span class="sd">        \lambda = \begin{bmatrix} \lambda_{n1}; &amp; \cdots \lambda_{nk}; &amp;</span>
<span class="sd">        \lambda_{t1}; &amp;</span>
<span class="sd">        \cdots \lambda_{tk}; \end{bmatrix}\,,</span>

<span class="sd">    whereas ``sappy`` accepts decision variables in format</span>

<span class="sd">    .. math::</span>

<span class="sd">        \lambda_s = \begin{bmatrix} \lambda_{t1}; &amp; \lambda_{n1}; &amp;</span>
<span class="sd">        \cdots &amp; \lambda_{tk}; &amp; \lambda_{nk} \end{bmatrix}\,.</span>

<span class="sd">    This function returns matrix :math:`M` to map betweens the two as</span>

<span class="sd">    .. math::</span>

<span class="sd">        \lambda = M\lambda_s</span>

<span class="sd">    Args:</span>
<span class="sd">        n_cones: number of contacts :math:`0`</span>

<span class="sd">    Returns:</span>
<span class="sd">        ``(3 * n_cones, 3 * n_cones)`` reordering matrix.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=E1103</span>
    <span class="n">matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span> <span class="o">*</span> <span class="n">n_cones</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">n_cones</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">cone</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cones</span><span class="p">):</span>
        <span class="n">matrix</span><span class="p">[</span><span class="n">cone</span><span class="p">][</span><span class="mi">3</span> <span class="o">*</span> <span class="n">cone</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">matrix</span><span class="p">[</span><span class="n">n_cones</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">cone</span><span class="p">][</span><span class="mi">3</span> <span class="o">*</span> <span class="n">cone</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">matrix</span><span class="p">[</span><span class="n">n_cones</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">cone</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="mi">3</span> <span class="o">*</span> <span class="n">cone</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">matrix</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Mathew Halm &amp; DAIR Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>