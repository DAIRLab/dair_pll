"""Wrappers for Drake/ContactNets multibody experiments."""
import time
from abc import ABC
from dataclasses import field, dataclass
from enum import Enum
from typing import Optional, cast, Dict
import pdb

import torch
from torch import Tensor
from torch.utils.data import DataLoader

from dair_pll import file_utils
from dair_pll import vis_utils
from dair_pll.deep_learnable_system import DeepLearnableExperiment
from dair_pll.drake_system import DrakeSystem
from dair_pll.experiment import SupervisedLearningExperiment, \
    LEARNED_SYSTEM_NAME, PREDICTION_NAME, TARGET_NAME
from dair_pll.experiment_config import SystemConfig, \
    SupervisedLearningExperimentConfig
from dair_pll.multibody_learnable_system import \
    MultibodyLearnableSystem, W_COMP, W_PEN, W_DISS
from dair_pll.system import System, SystemSummary


@dataclass
class DrakeSystemConfig(SystemConfig):
    urdfs: Dict[str, str] = field(default_factory=dict)


class MultibodyLosses(Enum):
    PREDICTION_LOSS = 1
    CONTACTNETS_LOSS = 2


@dataclass
class MultibodyLearnableSystemConfig(DrakeSystemConfig):
    loss: MultibodyLosses = MultibodyLosses.PREDICTION_LOSS
    """Whether to use ContactNets or prediction loss."""
    inertia_mode: int = 4
    """What inertial parameters to learn."""


@dataclass
class DrakeMultibodyLearnableExperimentConfig(SupervisedLearningExperimentConfig
                                             ):
    visualize_learned_geometry: bool = True
    """Whether to use learned geometry in trajectory overlay visualization."""


class DrakeExperiment(SupervisedLearningExperiment, ABC):
    base_drake_system: Optional[DrakeSystem]
    visualization_system: Optional[DrakeSystem]

    def __init__(self, config: SupervisedLearningExperimentConfig) -> None:
        super().__init__(config)
        self.base_drake_system = None

    def get_drake_system(self) -> DrakeSystem:
        has_property = hasattr(self, 'base_drake_system')
        if not has_property or self.base_drake_system is None:
            base_config = cast(DrakeSystemConfig, self.config.base_config)
            dt = self.config.data_config.dt
            self.base_drake_system = DrakeSystem(base_config.urdfs, dt)
        return self.base_drake_system

    def get_base_system(self) -> System:
        return self.get_drake_system()

    def get_learned_drake_system(
            self, learned_system: System) -> Optional[DrakeSystem]:
        r"""If possible, constructs a :py:class:`DrakeSystem` -equivalent
        model of the given learned system, such as when the learned system is a
        :py:class:`MultibodyLearnableSystem`\ .

        Args:
            learned_system: System being learned in experiment.

        Returns:
            Drake version of learned system.
        """
        return None

    def visualizer_regeneration_is_required(self) -> bool:
        """Checks if visualizer should be regenerated, e.g. if learned
        geometries have been updated and need to be pushed to the visulizer.
        """
        return False

    def get_visualization_system(self, learned_system: System) -> DrakeSystem:
        """Generate a dummy :py:class:`DrakeSystem` for visualizing comparisons
        between trajectories generated by the base system and something else,
        e.g. data.

        Implemented as a thin wrapper of
        ``vis_utils.generate_visualization_system()``, which generates a
        drake system where each model in the base
        :py:class:`DrakeSystem` has a duplicate, and visualization
        elements are repainted for visual distinction.

        Args:
            learned_system: Current trained learnable system.

        Returns:
            New :py:class:`DrakeSystem` with doubled state and repainted
            elements.
        """
        # Generate a new visualization system if it needs to use the updated
        # geometry, or if it hasn't been created yet.
        regeneration_is_required = self.visualizer_regeneration_is_required()
        if regeneration_is_required or self.visualization_system is None:
            visualization_file = file_utils.get_trajectory_video_filename(
                self.config.storage, self.config.run_name)
            base_system = self.get_drake_system()
            self.visualization_system = \
                vis_utils.generate_visualization_system(
                    base_system,
                    visualization_file,
                    learned_system=self.get_learned_drake_system(learned_system)
                )

        return self.visualization_system

    def base_and_learned_comparison_summary(
            self, statistics: Dict, learned_system: System) -> SystemSummary:
        r"""Extracts a :py:class:`~dair_pll.system.SystemSummary` that compares
        the base system to the learned system.

        For Drake-based experiments, this comparison is implemented as
        overlaid videos of corresponding ground-truth and predicted
        trajectories. The nature of this video is described further in
        :py:mod:`dair_pll.vis_utils`\ .

        Args:
            statistics: Dictionary of training statistics.
            learned_system: Most updated version of learned system during
              training.

        Returns:
            Summary containing overlaid video(s).
        """

        visualization_system = self.get_visualization_system(learned_system)

        space = self.get_drake_system().space
        videos = {}
        for traj_num in [0]:
            for set_name in ['train', 'valid']:
                target_key = f'{set_name}_{LEARNED_SYSTEM_NAME}' + \
                             f'_{TARGET_NAME}'
                prediction_key = f'{set_name}_{LEARNED_SYSTEM_NAME}' + \
                                 f'_{PREDICTION_NAME}'
                if not target_key in statistics:
                    continue
                target_trajectory = Tensor(statistics[target_key][traj_num])
                prediction_trajectory = Tensor(
                    statistics[prediction_key][traj_num])
                visualization_trajectory = torch.cat(
                    (space.q(target_trajectory), space.q(prediction_trajectory),
                     space.v(target_trajectory),
                     space.v(prediction_trajectory)), -1)
                video, framerate = vis_utils.visualize_trajectory(
                    visualization_system, visualization_trajectory)
                videos[f'{set_name}_trajectory_prediction_{traj_num}'] = \
                    (video, framerate)
        return SystemSummary(scalars={}, videos=videos, meshes={})


class DrakeDeepLearnableExperiment(DrakeExperiment, DeepLearnableExperiment):
    pass


class DrakeMultibodyLearnableExperiment(DrakeExperiment):

    def __init__(self, config: DrakeMultibodyLearnableExperimentConfig) -> None:
        super().__init__(config)
        learnable_config = cast(MultibodyLearnableSystemConfig,
                                self.config.learnable_config)
        if learnable_config.loss == MultibodyLosses.CONTACTNETS_LOSS:
            self.loss_callback = self.contactnets_loss

    def get_learned_system(self, _: Tensor) -> MultibodyLearnableSystem:
        learnable_config = cast(MultibodyLearnableSystemConfig,
                                self.config.learnable_config)
        output_dir = file_utils.get_learned_urdf_dir(self.config.storage,
                                                     self.config.run_name)
        return MultibodyLearnableSystem(learnable_config.urdfs,
                                        self.config.data_config.dt,
                                        learnable_config.inertia_mode,
                                        output_urdfs_dir=output_dir)

    def write_to_tensorboard(self, epoch: int, learned_system: System,
                             statistics: Dict) -> None:
        """In addition to extracting and writing training progress summary via
        the parent :py:meth:`Experiment.write_to_tensorboard` method, also make
        a breakdown plot of loss contributions for the ContactNets loss
        formulation.

        Notes:
            TODO this is no longer used after the switch to wandb, which doesn't
            do the overlaid scalars functionality.  It would be nice to have
            something like this implemented for debugging purposes.

        Args:
            epoch: Current epoch.
            learned_system: System being trained.
            statistics: Summary statistics for learning process.
        """
        assert self.tensorboard_manager is not None

        # Begin recording wall-clock logging time.
        start_log_time = time.time()
        epoch_vars, system_summary = self.build_epoch_vars_and_system_summary(
                                            learned_system, statistics)

        # Start computing individual loss components.
        # First get a batch sized portion of the shuffled training set.
        train_traj_set, _, _ = self.data_manager.get_trajectory_split()
        train_dataloader = DataLoader(
            train_traj_set.slices,
            batch_size=self.config.optimizer_config.batch_size.value,
            shuffle=True)

        # Calculate the average loss components.
        losses_pred, losses_comp, losses_pen, losses_diss = [], [], [], []
        for xy_i in train_dataloader:
            x_i: Tensor = xy_i[0]
            y_i: Tensor = xy_i[1]

            x = x_i[..., -1, :]
            x_plus = y_i[..., 0, :]
            u = torch.zeros(x.shape[:-1] + (0,))

            loss_pred, loss_comp, loss_pen, loss_diss = \
                learned_system.calculate_contactnets_loss_terms(x, u, x_plus)

            losses_pred.append(loss_pred.clone().detach())
            losses_comp.append(loss_comp.clone().detach())
            losses_pen.append(loss_pen.clone().detach())
            losses_diss.append(loss_diss.clone().detach())

        # Calculate average and scale by hyperparameter weights.
        avg_loss_pred = cast(Tensor, sum(losses_pred) \
                            / len(losses_pred)).mean()
        avg_loss_comp = W_COMP*cast(Tensor, sum(losses_comp) \
                            / len(losses_comp)).mean()
        avg_loss_pen = W_PEN*cast(Tensor, sum(losses_pen) \
                            / len(losses_pen)).mean()
        avg_loss_diss = W_DISS*cast(Tensor, sum(losses_diss) \
                            / len(losses_diss)).mean()

        avg_loss_total = torch.sum(avg_loss_pred + avg_loss_comp + \
                                   avg_loss_pen + avg_loss_diss)

        loss_breakdown = {'loss_total': avg_loss_total,
                          'loss_pred': avg_loss_pred,
                          'loss_comp': avg_loss_comp,
                          'loss_pen': avg_loss_pen,
                          'loss_diss': avg_loss_diss}

        # Include the loss breakdown into system summary.
        system_summary.overlaid_scalars = [loss_breakdown]
        
        # Overwrite the logging time.
        logging_duration = time.time() - start_log_time
        epoch_vars[LOGGING_DURATION] = logging_duration

        self.tensorboard_manager.update(epoch, epoch_vars,
                                        system_summary.videos,
                                        system_summary.meshes,
                                        system_summary.overlaid_scalars)

    def visualizer_regeneration_is_required(self) -> bool:
        return cast(DrakeMultibodyLearnableExperimentConfig,
                    self.config).visualize_learned_geometry

    def get_learned_drake_system(
            self, learned_system: System) -> Optional[DrakeSystem]:
        visualize_learned_geometry = cast(
            DrakeMultibodyLearnableExperimentConfig,
            self.config).visualize_learned_geometry

        if visualize_learned_geometry:
            new_urdfs = cast(MultibodyLearnableSystem,
                             learned_system).generate_updated_urdfs()
            return DrakeSystem(new_urdfs, self.get_drake_system().dt)
        return None

    def contactnets_loss(self,
                         x_past: Tensor,
                         x_future: Tensor,
                         system: System,
                         keep_batch: bool = False) -> Tensor:
        r""" :py:data:`~dair_pll.experiment.LossCallbackCallable`
        which applies the ContactNets [1] loss to the system.

        References:
            [1] S. Pfrommer*, M. Halm*, and M. Posa. "ContactNets: Learning
            Discontinuous Contact Dynamics with Smooth, Implicit
            Representations," Conference on Robotic Learning, 2020,
            https://proceedings.mlr.press/v155/pfrommer21a.html
        """
        assert isinstance(system, MultibodyLearnableSystem)
        x = x_past[..., -1, :]
        # pylint: disable=E1103
        u = torch.zeros(x.shape[:-1] + (0,))
        x_plus = x_future[..., 0, :]
        loss = system.contactnets_loss(x, u, x_plus)
        if not keep_batch:
            loss = loss.mean()
        return loss
